{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cindywong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import PorterStemmer\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Location</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Text</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/6/2017 05:00</td>\n",
       "      <td>Camp McGregor, NM</td>\n",
       "      <td>Light</td>\n",
       "      <td>10 minute</td>\n",
       "      <td>Light seen over mountain's east of Camp McGre...</td>\n",
       "      <td>Report appears to us to be consistent with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017 11:30</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Disk</td>\n",
       "      <td>3 second</td>\n",
       "      <td>Flying saucer descends, possibly lands in Nor...</td>\n",
       "      <td>We would like to communicate with this witne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/4/2017 21:27</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>15 second</td>\n",
       "      <td>Orange round sphere.  Orange glowing sphere f...</td>\n",
       "      <td>We have amended the time above, to reflect a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/4/2017 18:30</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Teardrop</td>\n",
       "      <td>5 minute</td>\n",
       "      <td>Flying corkscrews  Looking to th east at abou...</td>\n",
       "      <td>Source of the report elects to remain anonymous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/4/2017 04:50</td>\n",
       "      <td>Taft, CA</td>\n",
       "      <td>Changing</td>\n",
       "      <td>20 second</td>\n",
       "      <td>I'm a truck driver and I've seen the reddish/...</td>\n",
       "      <td>Witness indicates \"Taft, Indiana\" in origina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Datetime             Location       Shape   Duration  \\\n",
       "0   5/6/2017 05:00     Camp McGregor, NM       Light   10 minute   \n",
       "1   5/5/2017 11:30            Austin, TX        Disk    3 second   \n",
       "2   5/4/2017 21:27           Phoenix, AZ      Circle   15 second   \n",
       "3   5/4/2017 18:30           Phoenix, AZ    Teardrop    5 minute   \n",
       "4   5/4/2017 04:50              Taft, CA    Changing   20 second   \n",
       "\n",
       "                                                Text  \\\n",
       "0   Light seen over mountain's east of Camp McGre...   \n",
       "1   Flying saucer descends, possibly lands in Nor...   \n",
       "2   Orange round sphere.  Orange glowing sphere f...   \n",
       "3   Flying corkscrews  Looking to th east at abou...   \n",
       "4   I'm a truck driver and I've seen the reddish/...   \n",
       "\n",
       "                                               Notes  \n",
       "0    Report appears to us to be consistent with t...  \n",
       "1    We would like to communicate with this witne...  \n",
       "2    We have amended the time above, to reflect a...  \n",
       "3    Source of the report elects to remain anonymous  \n",
       "4    Witness indicates \"Taft, Indiana\" in origina...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2736 rows of dataset\n",
    "df = pd.read_csv('data/ufo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2736 entries, 0 to 2735\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Datetime  2736 non-null   object\n",
      " 1   Location  2736 non-null   object\n",
      " 2   Shape     2736 non-null   object\n",
      " 3   Duration  2736 non-null   object\n",
      " 4   Text      2736 non-null   object\n",
      " 5   Notes     2736 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 128.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Light seen over mountain's east of Camp McGre...\n",
       "1        Flying saucer descends, possibly lands in Nor...\n",
       "2        Orange round sphere.  Orange glowing sphere f...\n",
       "3        Flying corkscrews  Looking to th east at abou...\n",
       "4        I'm a truck driver and I've seen the reddish/...\n",
       "                              ...                        \n",
       "2731     Brightly lit craft flew and hovered right in ...\n",
       "2732     Triangle bright flashing white light, releasi...\n",
       "2733     Light, orange, red, fast speed.  My gf and I ...\n",
       "2734     Three circular, flashing UFO's moving in erra...\n",
       "2735     Fireball came in from east and made sharp tur...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, doc in enumerate(text_pre):\n",
    "#     #df.iloc[:, 5].str.replace('\\d+', '') # for digits\n",
    "#     df.iloc[idx, 4] = doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].str.replace('\\d+', '') # for digits\n",
    "df['Text'] = df['Text'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\s]+', '') # for punctuation\n",
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        light seen over mountain east  camp mcgregor ...\n",
       "1        flying saucer descends possibly lands  north ...\n",
       "2        orange round sphere  orange glowing sphere fl...\n",
       "3        flying corkscrews  looking   east  about   sa...\n",
       "4          truck driver and  seen the reddishorange ba...\n",
       "                              ...                        \n",
       "2731     brightly lit craft flew and hovered right  fr...\n",
       "2732     triangle bright flashing white light releasin...\n",
       "2733     light orange red fast speed    and  were look...\n",
       "2734     three circular flashing ufo moving  erratic p...\n",
       "2735     fireball came  from east and made sharp turn ...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [pipelinize source](https://evisionindia.wordpress.com/2020/03/06/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-learn-how-to-tokenize-lemmatize-remove-stop-words-and-punctuation-with-sklearn-pipelines/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from string import *\n",
    "\n",
    "# class PorterTokenizer:\n",
    "#      def __init__(self):\n",
    "            \n",
    "#             self.ps = PorterStemmer()\n",
    "#             self.lower      = lower\n",
    "#             self.strip      = strip\n",
    "#             self.stopwords  = stopwords or set(sw.words('english'))\n",
    "#             self.punct      = punct or set(string.punctuation)\n",
    "#             self.lemmatizer = WordNetLemmatizer()\n",
    "#      def __call__(self, doc):\n",
    "#          return [self.ps.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import word_tokenize          \n",
    "# from nltk.stem import WordNetLemmatizer \n",
    "# class LemmaTokenizer(object):\n",
    "#     def __init__(self):\n",
    "#         self.wnl = WordNetLemmatizer()\n",
    "#     def __call__(self, articles):\n",
    "#         return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "# tf_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "#                                 strip_accents = 'unicode', # works \n",
    "#                                 stop_words = 'english', # works\n",
    "#                                 lowercase = True, # works\n",
    "#                                 max_df = 0.5, # works\n",
    "#                                 min_df = 10) # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "n_features=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', max_features=n_features,\n",
    "                       ngram_range=(1,2),\n",
    "                       tokenizer=LemmaTokenizer(),\n",
    "                       strip_accents = 'unicode', # works \n",
    "                       lowercase = True, # works\n",
    "                       max_df = 0.5, # works\n",
    "                       min_df = 10 # works\n",
    "                       #, tokenizer=PorterTokenizer()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2736, 3098)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vect.fit_transform(df['Text'])\n",
    "V = words.toarray()\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.46496217148482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components)\n",
    "nmf.fit(V)\n",
    "W = nmf.transform(V)\n",
    "H = nmf.components_\n",
    "\n",
    "nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3098)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able', 'abruptly', 'absolutely', 'absolutely sound', 'accelerated']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: like, looked, just, saw, star, time, went, look, looked like, night\n",
      "2: provides, information, provides contact, contact information, contact, anonymous provides, witness elect, bright, witness provides, disappeared\n",
      "3: launch, missile, missile launch, note navy, navy missile, navy, blue, bright, cloud, white\n",
      "4: minute, minute later, minute nuforc, later, sky minute, watched, stationary, minute moved, stayed, hovered\n",
      "5: object, object wa, appeared, shaped object, photo, video, flying, shaped, object appeared, high\n",
      "6: source, source report, report, note source, report elect, remain anonymous, report indicates, date approximate, note information, information provided\n",
      "7: craft, red, white, white light, red light, flashing, triangle, low, flying, bright white\n",
      "8: orange, orange light, east, moving, west, fireball, bright orange, orb, north, south\n",
      "9: second, flash, second nuforc, green, second later, later, meteor, disappeared, second wa, second disappeared\n",
      "10: date, approximate, indicates, indicates date, witness indicates, date sighting, sighting approximate, sighting, year, ufo\n"
     ]
    }
   ],
   "source": [
    "index_val = np.argsort(H)[:, -1:-11:-1]\n",
    "\n",
    "for i, lat_feat in enumerate(index_val):\n",
    "    print('%d: %s'%(i+1,', '.join([feature_names[n] for n in lat_feat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.584951s\n",
      "Explained variance of the SVD step: 6%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "# Vectorizer results are normalized, which makes KMeans behave as\n",
    "# spherical k-means for better results. Since LSA/SVD results are\n",
    "# not normalized, we have to redo the normalization.\n",
    "svd = TruncatedSVD(n_components)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X = lsa.fit_transform(words)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "    int(explained_variance * 100)))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(max_iter=100, n_clusters=10, n_init=1, verbose=False)\n",
      "done in 0.171s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=10, init='k-means++', max_iter=100, n_init=1,\n",
    "            verbose=False)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "# print(\"Adjusted Rand-Index: %.3f\"\n",
    "#       % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67460592,  0.17790962,  0.01296322,  0.03217064,  0.04473398,\n",
       "        -0.09893726,  0.38932031,  0.26785883,  0.10183356,  0.04491865],\n",
       "       [ 0.69603992,  0.0181176 , -0.08183118, -0.00890915, -0.06289363,\n",
       "        -0.04708611, -0.31576178,  0.35118151,  0.07361176, -0.1112587 ],\n",
       "       [ 0.74655288,  0.18387593, -0.00842903, -0.00325309,  0.3906447 ,\n",
       "         0.11267978, -0.06311554, -0.0595771 , -0.07664136,  0.11868286],\n",
       "       [ 0.67019299,  0.06136659,  0.1790519 , -0.06855207, -0.02738174,\n",
       "        -0.18477233, -0.04170666, -0.19724955,  0.34532481, -0.0252963 ],\n",
       "       [ 0.46940764, -0.2904576 ,  0.60879164, -0.11577357, -0.05811764,\n",
       "         0.09781153,  0.03390593,  0.05367022, -0.08212395, -0.00722883],\n",
       "       [ 0.6487843 , -0.362718  , -0.29556903,  0.01278014, -0.21750306,\n",
       "         0.04304135,  0.00510381, -0.01572252,  0.08924045,  0.26576682],\n",
       "       [ 0.56895269,  0.13122338, -0.14753645,  0.03675873, -0.26106528,\n",
       "         0.46966032,  0.09891121, -0.14555687,  0.00111624, -0.22025523],\n",
       "       [ 0.73585638, -0.22157989, -0.14088269,  0.01388002,  0.37634327,\n",
       "         0.07792025, -0.0040831 , -0.03849014, -0.01580343, -0.06258055],\n",
       "       [ 0.70003163,  0.47095908,  0.08171218,  0.01428684, -0.10102837,\n",
       "        -0.08467592, -0.09193978, -0.05712616, -0.08794166,  0.11050547],\n",
       "       [ 0.79679845, -0.12924001, -0.10466392, -0.00767599, -0.07989409,\n",
       "        -0.24713706,  0.03240061, -0.1144314 , -0.15179384, -0.13292409]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 1: object object wa appeared moving time\n",
      "Cluster 2: provides information provides contact contact information witness elect\n",
      "Cluster 3: launch missile missile launch note navy navy missile\n",
      "Cluster 4: minute like star bright looked\n",
      "Cluster 5: second bright white green red\n",
      "Cluster 6: like saw just looked object\n",
      "Cluster 7: date approximate indicates indicates date sighting\n",
      "Cluster 8: source report source report note source report elect\n",
      "Cluster 9: orange moving witness elect orange light second\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "#     else:\n",
    "#         order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vect.get_feature_names()\n",
    "for i in range(1, n_components):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
